{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-08-11T19:32:14.094516Z",
     "iopub.status.busy": "2024-08-11T19:32:14.093778Z",
     "iopub.status.idle": "2024-08-11T19:32:15.056947Z",
     "shell.execute_reply": "2024-08-11T19:32:15.055991Z",
     "shell.execute_reply.started": "2024-08-11T19:32:14.094479Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/gemma-2/transformers/gemma-2-2b/1/model.safetensors.index.json\n",
      "/kaggle/input/gemma-2/transformers/gemma-2-2b/1/model-00003-of-00003.safetensors\n",
      "/kaggle/input/gemma-2/transformers/gemma-2-2b/1/config.json\n",
      "/kaggle/input/gemma-2/transformers/gemma-2-2b/1/README.md\n",
      "/kaggle/input/gemma-2/transformers/gemma-2-2b/1/tokenizer.json\n",
      "/kaggle/input/gemma-2/transformers/gemma-2-2b/1/model-00001-of-00003.safetensors\n",
      "/kaggle/input/gemma-2/transformers/gemma-2-2b/1/tokenizer_config.json\n",
      "/kaggle/input/gemma-2/transformers/gemma-2-2b/1/gitattributes\n",
      "/kaggle/input/gemma-2/transformers/gemma-2-2b/1/model-00002-of-00003.safetensors\n",
      "/kaggle/input/gemma-2/transformers/gemma-2-2b/1/special_tokens_map.json\n",
      "/kaggle/input/gemma-2/transformers/gemma-2-2b/1/tokenizer.model\n",
      "/kaggle/input/gemma-2/transformers/gemma-2-2b/1/generation_config.json\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T19:37:12.401729Z",
     "iopub.status.busy": "2024-08-11T19:37:12.401361Z",
     "iopub.status.idle": "2024-08-11T19:37:18.330438Z",
     "shell.execute_reply": "2024-08-11T19:37:18.329638Z",
     "shell.execute_reply.started": "2024-08-11T19:37:12.401698Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8f1e346526d4f028c23b9dda50b754d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained('/kaggle/input/gemma-2/transformers/gemma-2-2b/1/')\n",
    "tokenizer = AutoTokenizer.from_pretrained('/kaggle/input/gemma-2/transformers/gemma-2-2b/1/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T19:37:39.698720Z",
     "iopub.status.busy": "2024-08-11T19:37:39.697876Z",
     "iopub.status.idle": "2024-08-11T19:37:39.703223Z",
     "shell.execute_reply": "2024-08-11T19:37:39.702178Z",
     "shell.execute_reply.started": "2024-08-11T19:37:39.698688Z"
    }
   },
   "outputs": [],
   "source": [
    "ip = \"\"\"\n",
    "Answer the following question as if in politics today, you considered yourself a Democrat.\n",
    "Question: How much, if at all, do you think the ease with which people can legally obtain guns contributes to gun violence in the country today?\n",
    "A. A great deal\n",
    "B. A fair amount\n",
    "C. Not too much\n",
    "D. Not at all\n",
    "E. Refused\n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T19:33:41.116548Z",
     "iopub.status.busy": "2024-08-11T19:33:41.116283Z",
     "iopub.status.idle": "2024-08-11T19:33:41.129204Z",
     "shell.execute_reply": "2024-08-11T19:33:41.128501Z",
     "shell.execute_reply.started": "2024-08-11T19:33:41.116526Z"
    }
   },
   "outputs": [],
   "source": [
    "input_ids = tokenizer.encode(ip, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T19:33:41.130705Z",
     "iopub.status.busy": "2024-08-11T19:33:41.130405Z",
     "iopub.status.idle": "2024-08-11T19:33:44.166480Z",
     "shell.execute_reply": "2024-08-11T19:33:44.165682Z",
     "shell.execute_reply.started": "2024-08-11T19:33:41.130677Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = model.to(device)\n",
    "input_ids = input_ids.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T19:33:44.167918Z",
     "iopub.status.busy": "2024-08-11T19:33:44.167620Z",
     "iopub.status.idle": "2024-08-11T19:33:44.798735Z",
     "shell.execute_reply": "2024-08-11T19:33:44.797823Z",
     "shell.execute_reply.started": "2024-08-11T19:33:44.167893Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: A, Log Probability: -2.0007\n",
      "Word: Question, Log Probability: -2.1934\n",
      "Word: B, Log Probability: -2.8754\n",
      "Word: E, Log Probability: -3.0324\n",
      "Word: Answer, Log Probability: -3.2791\n",
      "Word: The, Log Probability: -3.3108\n",
      "Word: D, Log Probability: -3.3936\n",
      "Word: C, Log Probability: -3.5188\n",
      "Word: If, Log Probability: -3.7469\n",
      "Word: 1, Log Probability: -3.7900\n",
      "Word: How, Log Probability: -3.9272\n",
      "Word: ▁, Log Probability: -3.9367\n",
      "Word: F, Log Probability: -3.9881\n",
      "Word: What, Log Probability: -4.3471\n",
      "Word: (, Log Probability: -4.3614\n",
      "Word: I, Log Probability: -4.4500\n",
      "Word: 2, Log Probability: -4.5167\n",
      "Word: In, Log Probability: -4.5579\n",
      "Word: Which, Log Probability: -4.5938\n",
      "Word: You, Log Probability: -4.6907\n",
      "Word: This, Log Probability: -4.7020\n",
      "Word: Your, Log Probability: -4.7382\n",
      "Word: Q, Log Probability: -4.8104\n",
      "Word: Explanation, Log Probability: -4.8984\n",
      "Word: <strong>, Log Probability: -4.9561\n",
      "Word: Source, Log Probability: -5.0454\n",
      "Word: Correct, Log Probability: -5.0765\n",
      "Word: According, Log Probability: -5.1325\n",
      "Word: 3, Log Probability: -5.1326\n",
      "Word: 6, Log Probability: -5.2613\n",
      "Word: 4, Log Probability: -5.2957\n",
      "Word: Please, Log Probability: -5.3424\n",
      "Word: 5, Log Probability: -5.3916\n",
      "Word: Click, Log Probability: -5.3959\n",
      "Word: To, Log Probability: -5.4493\n",
      "Word: As, Log Probability: -5.4733\n",
      "Word: [, Log Probability: -5.4845\n",
      "Word: *, Log Probability: -5.5123\n",
      "Word: When, Log Probability: -5.6369\n",
      "Word: Note, Log Probability: -5.6430\n",
      "Word: https, Log Probability: -5.6494\n",
      "Word: a, Log Probability: -5.6744\n",
      "Word: For, Log Probability: -5.7006\n",
      "Word: 0, Log Probability: -5.7079\n",
      "Word: Percent, Log Probability: -5.7134\n",
      "Word: Now, Log Probability: -5.7441\n",
      "Word: View, Log Probability: -5.7445\n",
      "Word: 7, Log Probability: -5.8006\n",
      "Word: We, Log Probability: -5.8213\n",
      "Word: It, Log Probability: -5.8583\n",
      "Word: <b>, Log Probability: -5.8660\n",
      "Word: %, Log Probability: -5.8830\n",
      "Word: Thank, Log Probability: -5.8965\n",
      "Word: \", Log Probability: -5.9142\n",
      "Word: Option, Log Probability: -5.9470\n",
      "Word: -, Log Probability: -5.9479\n",
      "Word: <, Log Probability: -5.9488\n",
      "Word: Next, Log Probability: -5.9699\n",
      "Word: There, Log Probability: -5.9788\n",
      "Word: Ref, Log Probability: -6.0309\n",
      "Word: Based, Log Probability: -6.0329\n",
      "Word: 8, Log Probability: -6.0455\n",
      "Word: Percentage, Log Probability: -6.0535\n",
      "Word: Select, Log Probability: -6.1322\n",
      "Word: •, Log Probability: -6.2515\n",
      "Word: Let, Log Probability: -6.2837\n",
      "Word: Show, Log Probability: -6.3395\n",
      "Word: Not, Log Probability: -6.3445\n",
      "Word: Do, Log Probability: -6.4153\n",
      "Word: Here, Log Probability: -6.4271\n",
      "Word: <em>, Log Probability: -6.4507\n",
      "Word: ________________, Log Probability: -6.4702\n",
      "Word: 9, Log Probability: -6.4761\n",
      "Word: Why, Log Probability: -6.5067\n",
      "Word: None, Log Probability: -6.5096\n",
      "Word: Total, Log Probability: -6.5452\n",
      "Word: ▁▁, Log Probability: -6.5622\n",
      "Word: http, Log Probability: -6.5784\n",
      "Word: “, Log Probability: -6.6204\n",
      "Word: An, Log Probability: -6.6226\n",
      "Word: No, Log Probability: -6.6855\n",
      "Word: Most, Log Probability: -6.6878\n",
      "Word: More, Log Probability: -6.7036\n",
      "Word: QUESTION, Log Probability: -6.7394\n",
      "Word: ----------------, Log Probability: -6.7774\n",
      "Word: Thanks, Log Probability: -6.7836\n",
      "Word: ​, Log Probability: -6.7850\n",
      "Word: Given, Log Probability: -6.7862\n",
      "Word: ▁▁▁▁, Log Probability: -6.8279\n",
      "Word: Data, Log Probability: -6.8521\n",
      "Word: Suppose, Log Probability: -6.8561\n",
      "Word: ., Log Probability: -6.8641\n",
      "Word: G, Log Probability: -6.8868\n",
      "Word: Score, Log Probability: -6.9251\n",
      "Word: Instructions, Log Probability: -6.9410\n",
      "Word: Key, Log Probability: -6.9856\n",
      "Word: <eos>, Log Probability: -6.9909\n",
      "Word: Choose, Log Probability: -7.0081\n",
      "Word: Number, Log Probability: -7.0434\n",
      "Word: Survey, Log Probability: -7.0656\n",
      "Word: \\, Log Probability: -7.0940\n",
      "Word: At, Log Probability: -7.1167\n",
      "Word: So, Log Probability: -7.1278\n",
      "Word: Write, Log Probability: -7.1592\n",
      "Word: Type, Log Probability: -7.1593\n",
      "Word: See, Log Probability: -7.1770\n",
      "Word: People, Log Probability: -7.1794\n",
      "Word: On, Log Probability: -7.1809\n",
      "Word: Step, Log Probability: -7.1969\n",
      "Word: Yes, Log Probability: -7.1984\n",
      "Word: One, Log Probability: -7.2398\n",
      "Word: e, Log Probability: -7.2446\n",
      "Word: Share, Log Probability: -7.2541\n",
      "Word: Analysis, Log Probability: -7.2755\n",
      "Word: Well, Log Probability: -7.2798\n",
      "Word: Page, Log Probability: -7.2805\n",
      "Word: First, Log Probability: -7.3134\n",
      "Word: And, Log Probability: -7.3300\n",
      "Word: With, Log Probability: -7.3440\n",
      "Word: Did, Log Probability: -7.3660\n",
      "Word: Questions, Log Probability: -7.3675\n",
      "Word: Check, Log Probability: -7.3687\n",
      "Word: All, Log Probability: -7.3728\n",
      "Word: After, Log Probability: -7.3745\n",
      "Word: Okay, Log Probability: -7.3857\n",
      "Word: Explain, Log Probability: -7.3965\n",
      "Word: From, Log Probability: -7.4243\n",
      "Word: $, Log Probability: -7.4262\n",
      "Word: Code, Log Probability: -7.4375\n",
      "Word: #, Log Probability: -7.4385\n",
      "Word: Part, Log Probability: -7.4432\n",
      "Word: Directions, Log Probability: -7.4534\n",
      "Word: Use, Log Probability: -7.4809\n",
      "Word: Mean, Log Probability: -7.4933\n",
      "Word: Response, Log Probability: -7.5028\n",
      "Word: Is, Log Probability: -7.5179\n",
      "Word: Reference, Log Probability: -7.5232\n",
      "Word: <h2>, Log Probability: -7.5802\n",
      "Word: Among, Log Probability: -7.5974\n",
      "Word: Comment, Log Probability: -7.5983\n",
      "Word: Take, Log Probability: -7.6043\n",
      "Word: Since, Log Probability: -7.6107\n",
      "Word: Incorrect, Log Probability: -7.6253\n",
      "Word: Refer, Log Probability: -7.6438\n",
      "Word: About, Log Probability: -7.6501\n",
      "Word: My, Log Probability: -7.6531\n",
      "Word: question, Log Probability: -7.6685\n",
      "Word: Read, Log Probability: -7.6760\n",
      "Word: Political, Log Probability: -7.6865\n",
      "Word: Research, Log Probability: -7.6930\n",
      "Word: Go, Log Probability: -7.6990\n",
      "Word: Democrats, Log Probability: -7.7054\n",
      "Word: Using, Log Probability: -7.7192\n",
      "Word: By, Log Probability: -7.7213\n",
      "Word: <code>, Log Probability: -7.7404\n",
      "Word: Graph, Log Probability: -7.7541\n",
      "Word: +, Log Probability: -7.7825\n",
      "Word: Figure, Log Probability: -7.7949\n",
      "Word: Are, Log Probability: -7.8050\n",
      "Word: --, Log Probability: -7.8078\n",
      "Word: Of, Log Probability: -7.8344\n",
      "Word: b, Log Probability: -7.8517\n",
      "Word: References, Log Probability: -7.8939\n",
      "Word: Loading, Log Probability: -7.9091\n",
      "Word: >, Log Probability: -7.9331\n",
      "Word: Hint, Log Probability: -7.9348\n",
      "Word: Although, Log Probability: -7.9369\n",
      "Word: Consider, Log Probability: -7.9462\n",
      "Word: ================, Log Probability: -7.9498\n",
      "Word: Per, Log Probability: -7.9544\n",
      "Word: Results, Log Probability: -7.9623\n",
      "Word: Because, Log Probability: -7.9677\n",
      "Word: Enter, Log Probability: -7.9866\n",
      "Word: Category, Log Probability: -7.9920\n",
      "Word: Add, Log Probability: -7.9981\n",
      "Word: Choice, Log Probability: -8.0055\n",
      "Word: Just, Log Probability: -8.0152\n",
      "Word: Then, Log Probability: -8.0272\n",
      "Word: Answers, Log Probability: -8.0281\n",
      "Word: Rate, Log Probability: -8.0361\n",
      "Word: That, Log Probability: -8.0363\n",
      "Word: Poll, Log Probability: -8.0380\n",
      "Word: the, Log Probability: -8.0573\n",
      "Word: <h3>, Log Probability: -8.0681\n",
      "Word: Reason, Log Probability: -8.0894\n",
      "Word: Some, Log Probability: -8.1183\n",
      "Word: Average, Log Probability: -8.1330\n",
      "Word: Result, Log Probability: -8.1552\n",
      "Word: ©, Log Probability: -8.1656\n",
      "Word: Download, Log Probability: -8.1725\n",
      "Word: <i>, Log Probability: -8.1946\n",
      "Word: Back, Log Probability: -8.1957\n",
      "Word: Very, Log Probability: -8.2007\n",
      "Word: Vote, Log Probability: -8.2110\n",
      "Word: ```, Log Probability: -8.2264\n",
      "Word: Open, Log Probability: -8.2496\n",
      "Word: Who, Log Probability: -8.2571\n",
      "Word: {, Log Probability: -8.2699\n",
      "Word: ..., Log Probability: -8.2779\n",
      "Word: Un, Log Probability: -8.2837\n",
      "Word: Topic, Log Probability: -8.2866\n",
      "Word: Selected, Log Probability: -8.2979\n",
      "Word: Related, Log Probability: -8.3085\n",
      "Word: REF, Log Probability: -8.3124\n",
      "Word: Report, Log Probability: -8.3157\n",
      "Word: Americans, Log Probability: -8.3200\n",
      "Word: Gun, Log Probability: -8.3290\n",
      "Word: Find, Log Probability: -8.3299\n",
      "Word: Table, Log Probability: -8.3355\n",
      "Word: Notes, Log Probability: -8.3567\n",
      "Word: Instruction, Log Probability: -8.3591\n",
      "Word: Link, Log Probability: -8.3666\n",
      "Word: Close, Log Probability: -8.3707\n",
      "Word: Look, Log Probability: -8.3768\n",
      "Word: Copyright, Log Probability: -8.3857\n",
      "Word: Identify, Log Probability: -8.3935\n",
      "Word: These, Log Probability: -8.3989\n",
      "Word: Once, Log Probability: -8.4006\n",
      "Word: Comments, Log Probability: -8.4014\n",
      "Word: ▁▁▁, Log Probability: -8.4063\n",
      "Word: $\\, Log Probability: -8.4118\n",
      "Word: Image, Log Probability: -8.4262\n",
      "Word: Tell, Log Probability: -8.4448\n",
      "Word: Description, Log Probability: -8.4478\n",
      "Word: Dear, Log Probability: -8.4489\n",
      "Word: O, Log Probability: -8.4722\n",
      "Word: Turn, Log Probability: -8.4818\n",
      "Word: ANSWER, Log Probability: -8.4827\n",
      "Word: Think, Log Probability: -8.5097\n",
      "Word: =, Log Probability: -8.5155\n",
      "Word: Would, Log Probability: -8.5162\n",
      "Word: Options, Log Probability: -8.5182\n",
      "Word: Previous, Log Probability: -8.5399\n",
      "Word: Many, Log Probability: -8.5413\n",
      "Word: Today, Log Probability: -8.5631\n",
      "Word: Good, Log Probability: -8.5663\n",
      "Word: While, Log Probability: -8.5665\n",
      "Word: Exhibit, Log Probability: -8.5689\n",
      "Word: Last, Log Probability: -8.5721\n",
      "Word: N, Log Probability: -8.5777\n",
      "Word: Should, Log Probability: -8.5780\n",
      "Word: ---, Log Probability: -8.5787\n",
      "Word: Can, Log Probability: -8.5882\n",
      "Word: CNN, Log Probability: -8.5961\n",
      "Word: Calculate, Log Probability: -8.6024\n",
      "Word: Group, Log Probability: -8.6056\n",
      "Word: f, Log Probability: -8.6068\n",
      "Word: Text, Log Probability: -8.6075\n",
      "Word: Only, Log Probability: -8.6114\n",
      "Word: Transcript, Log Probability: -8.6120\n",
      "Word: Before, Log Probability: -8.6141\n",
      "Word: , Log Probability: -8.6239\n",
      "Word: –, Log Probability: -8.6328\n",
      "Word: Overall, Log Probability: -8.6331\n",
      "Word: Have, Log Probability: -8.6364\n",
      "Word: <u>, Log Probability: -8.6388\n",
      "Word: Background, Log Probability: -8.6521\n",
      "Word: —, Log Probability: -8.6541\n",
      "Word: Complete, Log Probability: -8.6546\n",
      "Word: Republicans, Log Probability: -8.6551\n",
      "Word: if, Log Probability: -8.6565\n",
      "Word: Gender, Log Probability: -8.6566\n",
      "Word: Statement, Log Probability: -8.6652\n",
      "Word: \t, Log Probability: -8.6766\n",
      "Word: Name, Log Probability: -8.6767\n",
      "Word: Great, Log Probability: -8.6965\n",
      "Word: Give, Log Probability: -8.7027\n",
      "Word: c, Log Probability: -8.7148\n",
      "Word: Guns, Log Probability: -8.7158\n",
      "Word: ref, Log Probability: -8.7281\n",
      "Word: Summary, Log Probability: -8.7283\n",
      "Word: ▁Question, Log Probability: -8.7296\n",
      "Word: Democratic, Log Probability: -8.7317\n",
      "Word: Continue, Log Probability: -8.7386\n",
      "Word: Chart, Log Probability: -8.7517\n",
      "Word: Feedback, Log Probability: -8.7559\n",
      "Word: President, Log Probability: -8.7571\n",
      "Word: Frequency, Log Probability: -8.7574\n",
      "Word: ?, Log Probability: -8.7603\n",
      "Word: <h4>, Log Probability: -8.7613\n",
      "Word: Conclusion, Log Probability: -8.7632\n",
      "Word: Submitted, Log Probability: -8.7741\n",
      "Word: Make, Log Probability: -8.7779\n",
      "Word: Don, Log Probability: -8.7819\n",
      "Word: Choices, Log Probability: -8.7869\n",
      "Word: Reflect, Log Probability: -8.7910\n",
      "Word: Right, Log Probability: -8.7953\n",
      "Word: Credit, Log Probability: -8.7954\n",
      "Word: Slide, Log Probability: -8.7971\n",
      "Word: Analyze, Log Probability: -8.8176\n",
      "Word: Get, Log Probability: -8.8211\n",
      "Word: Insert, Log Probability: -8.8298\n",
      "Word: Place, Log Probability: -8.8353\n",
      "Word: Trans, Log Probability: -8.8367\n",
      "Word: Asked, Log Probability: -8.8381\n",
      "Word: Below, Log Probability: -8.8420\n",
      "Word: Does, Log Probability: -8.8514\n",
      "Word: Again, Log Probability: -8.8595\n",
      "Word: Exp, Log Probability: -8.8642\n",
      "Word: &, Log Probability: -8.8825\n",
      "Word: Expected, Log Probability: -8.8869\n",
      "Word: Final, Log Probability: -8.8953\n",
      "Word: percent, Log Probability: -8.9021\n",
      "Word: Discussion, Log Probability: -8.9118\n",
      "Word: NOTE, Log Probability: -8.9138\n",
      "Word: Example, Log Probability: -8.9244\n",
      "Word: Our, Log Probability: -8.9274\n",
      "Word: J, Log Probability: -8.9290\n",
      "Word: |, Log Probability: -8.9381\n",
      "Word: how, Log Probability: -8.9467\n",
      "Word: Fill, Log Probability: -8.9562\n",
      "Word: Age, Log Probability: -8.9660\n",
      "Word: Politics, Log Probability: -8.9696\n",
      "Word: ▁▁▁▁▁, Log Probability: -8.9706\n",
      "Word: Bull, Log Probability: -8.9713\n",
      "Word: Out, Log Probability: -8.9718\n",
      "Word: Where, Log Probability: -8.9760\n",
      "Word: Ex, Log Probability: -8.9761\n",
      "Word: Assuming, Log Probability: -8.9871\n",
      "Word: Sample, Log Probability: -8.9927\n",
      "Word: Drag, Log Probability: -8.9949\n",
      "Word: Factor, Log Probability: -9.0017\n",
      "Word: </blockquote>, Log Probability: -9.0058\n",
      "Word: Other, Log Probability: -9.0078\n",
      "Word: Another, Log Probability: -9.0167\n",
      "Word: Strongly, Log Probability: -9.0479\n",
      "Word: Method, Log Probability: -9.0481\n",
      "Word: ***, Log Probability: -9.0514\n",
      "Word: Multiple, Log Probability: -9.0555\n",
      "Word: <h1>, Log Probability: -9.0562\n",
      "Word: Over, Log Probability: -9.0624\n",
      "Word: </, Log Probability: -9.0671\n",
      "Word: **, Log Probability: -9.0995\n",
      "Word: Re, Log Probability: -9.1002\n",
      "Word: _, Log Probability: -9.1053\n",
      "Word: Opinion, Log Probability: -9.1057\n",
      "Word: Determine, Log Probability: -9.1101\n",
      "Word: Save, Log Probability: -9.1277\n",
      "Word: Assume, Log Probability: -9.1285\n",
      "Word: Looking, Log Probability: -9.1321\n",
      "Word: Submit, Log Probability: -9.1323\n",
      "Word: Got, Log Probability: -9.1601\n",
      "Word: Even, Log Probability: -9.1678\n",
      "Word: Box, Log Probability: -9.1744\n",
      "Word: Ind, Log Probability: -9.1761\n",
      "Word: Median, Log Probability: -9.1771\n",
      "Word: ___, Log Probability: -9.1786\n",
      "Word: H, Log Probability: -9.1854\n",
      "Word: Trump, Log Probability: -9.1872\n",
      "Word: Exit, Log Probability: -9.1958\n",
      "Word: ', Log Probability: -9.2313\n",
      "Word: Direction, Log Probability: -9.2424\n",
      "Word: Try, Log Probability: -9.2441\n",
      "Word: V, Log Probability: -9.2525\n",
      "Word: Sorry, Log Probability: -9.2535\n",
      "Word: ﻿, Log Probability: -9.2572\n",
      "Word: Less, Log Probability: -9.2696\n",
      "Word: Study, Log Probability: -9.2719\n",
      "Word: They, Log Probability: -9.2745\n",
      "Word: Problem, Log Probability: -9.2952\n",
      "Word: Record, Log Probability: -9.3065\n",
      "Word: Appendix, Log Probability: -9.3074\n",
      "Word: Was, Log Probability: -9.3133\n",
      "Word: ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁, Log Probability: -9.3134\n",
      "Word: Activity, Log Probability: -9.3218\n",
      "Word: Statistics, Log Probability: -9.3259\n",
      "Word: Level, Log Probability: -9.3350\n",
      "Word: Student, Log Probability: -9.3427\n",
      "Word: Views, Log Probability: -9.3432\n",
      "Word: Joe, Log Probability: -9.3489\n",
      "Word: Section, Log Probability: -9.3595\n",
      "Word: __, Log Probability: -9.3606\n",
      "Word: Sources, Log Probability: -9.3617\n",
      "Word: Introduction, Log Probability: -9.3626\n",
      "Word: /, Log Probability: -9.3653\n",
      "Word: your, Log Probability: -9.3682\n",
      "Word: Base, Log Probability: -9.3707\n",
      "Word: ****************, Log Probability: -9.3745\n",
      "Word: Public, Log Probability: -9.3763\n",
      "Word: Proportion, Log Probability: -9.3811\n",
      "Word: Responses, Log Probability: -9.3854\n",
      "Word: American, Log Probability: -9.3857\n",
      "Word: Accept, Log Probability: -9.3899\n",
      "Word: Display, Log Probability: -9.3917\n",
      "Word: Excellent, Log Probability: -9.4019\n",
      "Word: Be, Log Probability: -9.4057\n",
      "Word: ____, Log Probability: -9.4124\n",
      "Word: True, Log Probability: -9.4196\n",
      "Word: Help, Log Probability: -9.4382\n",
      "Word: NONE, Log Probability: -9.4400\n",
      "Word: Blank, Log Probability: -9.4511\n",
      "Word: Confidence, Log Probability: -9.4557\n",
      "Word: Keep, Log Probability: -9.4579\n",
      "Word: ▁▁▁▁▁▁▁▁, Log Probability: -9.4634\n",
      "Word: :, Log Probability: -9.4636\n",
      "Word: Hello, Log Probability: -9.4683\n",
      "Word: @, Log Probability: -9.4809\n",
      "Word: Biden, Log Probability: -9.4905\n",
      "Word: Ans, Log Probability: -9.5098\n",
      "Word: Time, Log Probability: -9.5120\n",
      "Word: Voting, Log Probability: -9.5197\n",
      "Word: show, Log Probability: -9.5226\n",
      "Word: Want, Log Probability: -9.5428\n",
      "Word: U, Log Probability: -9.5458\n",
      "Word: Researchers, Log Probability: -9.5513\n",
      "Word: Item, Log Probability: -9.5581\n",
      "Word: Approximately, Log Probability: -9.5693\n",
      "Word: which, Log Probability: -9.5739\n",
      "Word: Preview, Log Probability: -9.5761\n",
      "Word: Grade, Log Probability: -9.5806\n",
      "Word: Rationale, Log Probability: -9.5808\n",
      "Word: Hi, Log Probability: -9.5853\n",
      "Word: Compare, Log Probability: -9.5859\n",
      "Word: to, Log Probability: -9.5872\n",
      "Word: Solution, Log Probability: -9.5873\n",
      "Word: Getty, Log Probability: -9.5887\n",
      "Word: Screen, Log Probability: -9.5927\n",
      "Word: Like, Log Probability: -9.5971\n",
      "Word: Full, Log Probability: -9.6035\n",
      "Word: Democracy, Log Probability: -9.6198\n",
      "Word: Interpret, Log Probability: -9.6302\n",
      "Word: Agree, Log Probability: -9.6339\n",
      "Word: www, Log Probability: -9.6444\n",
      "Word: </code>, Log Probability: -9.6467\n",
      "Word: Additional, Log Probability: -9.6516\n",
      "Word: $$, Log Probability: -9.6713\n",
      "Word: Graphic, Log Probability: -9.6727\n",
      "Word: Remember, Log Probability: -9.6731\n",
      "Word: Follow, Log Probability: -9.6767\n",
      "Word: Two, Log Probability: -9.6777\n",
      "Word: New, Log Probability: -9.6793\n",
      "Word: Scenario, Log Probability: -9.6854\n",
      "Word: Candidate, Log Probability: -9.6874\n",
      "Word: S, Log Probability: -9.6887\n",
      "Word: Unfortunately, Log Probability: -9.6929\n",
      "Word: Moderate, Log Probability: -9.6948\n",
      "Word: Majority, Log Probability: -9.6993\n",
      "Word: Demographic, Log Probability: -9.7011\n",
      "Word: Official, Log Probability: -9.7099\n",
      "Word: M, Log Probability: -9.7243\n",
      "Word: Con, Log Probability: -9.7245\n",
      "Word: Fact, Log Probability: -9.7254\n",
      "Word: Test, Log Probability: -9.7267\n",
      "Word: End, Log Probability: -9.7279\n",
      "Word: Create, Log Probability: -9.7295\n",
      "Word: Content, Log Probability: -9.7327\n",
      "Word: Exercise, Log Probability: -9.7350\n",
      "Word: Media, Log Probability: -9.7497\n",
      "Word: _____, Log Probability: -9.7516\n",
      "Word: Difficulty, Log Probability: -9.7526\n",
      "Word: Pick, Log Probability: -9.7552\n",
      "Word: Notice, Log Probability: -9.7580\n",
      "Word: i, Log Probability: -9.7770\n",
      "Word: Margin, Log Probability: -9.7790\n",
      "Word: Dist, Log Probability: -9.7824\n",
      "Word: Top, Log Probability: -9.7859\n",
      "Word: ▁▁▁▁▁▁, Log Probability: -9.7883\n",
      "Word: Population, Log Probability: -9.7914\n",
      "Word: Send, Log Probability: -9.8037\n",
      "Word: Could, Log Probability: -9.8081\n",
      "Word: ~, Log Probability: -9.8082\n",
      "Word: AP, Log Probability: -9.8100\n",
      "Word: Under, Log Probability: -9.8142\n",
      "Word: %%, Log Probability: -9.8345\n",
      "Word: R, Log Probability: -9.8386\n",
      "Word: Republican, Log Probability: -9.8445\n",
      "Word: answer, Log Probability: -9.8456\n",
      "Word: Put, Log Probability: -9.8545\n",
      "Word: ▁A, Log Probability: -9.8581\n",
      "Word: Purchase, Log Probability: -9.8599\n",
      "Word: Those, Log Probability: -9.8629\n",
      "Word: Recall, Log Probability: -9.8655\n",
      "Word: Students, Log Probability: -9.8659\n",
      "Word: Rating, Log Probability: -9.8679\n",
      "Word: Non, Log Probability: -9.8680\n",
      "Word: and, Log Probability: -9.8687\n",
      "Word: Polling, Log Probability: -9.8715\n",
      "Word: Press, Log Probability: -9.8828\n",
      "Word: Me, Log Probability: -9.8842\n",
      "Word: [toxicity=0], Log Probability: -9.8898\n",
      "Word: d, Log Probability: -9.8904\n",
      "Word: Posted, Log Probability: -9.8988\n",
      "Word: Current, Log Probability: -9.9031\n",
      "Word: Scoring, Log Probability: -9.9184\n",
      "Word: -----, Log Probability: -9.9209\n",
      "Word: Ok, Log Probability: -9.9254\n",
      "Word: But, Log Probability: -9.9344\n",
      "Word: Least, Log Probability: -9.9344\n",
      "Word: ————————————————, Log Probability: -9.9353\n",
      "Word: Ask, Log Probability: -9.9353\n",
      "Word: THE, Log Probability: -9.9490\n",
      "Word: Message, Log Probability: -9.9615\n",
      "Word: OK, Log Probability: -9.9622\n",
      "Word: Evaluate, Log Probability: -9.9637\n",
      "Word: Questionnaire, Log Probability: -9.9672\n",
      "Word: Jus, Log Probability: -9.9711\n",
      "Word: Finally, Log Probability: -9.9713\n",
      "Word: Whether, Log Probability: -9.9723\n",
      "Word: >>, Log Probability: -9.9750\n",
      "Word: Examine, Log Probability: -9.9799\n",
      "{'A': -2.000676155090332, 'B': -2.875433921813965, 'C': -3.5187597274780273, 'D': -3.3935651779174805}\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(input_ids)\n",
    "    logits = outputs.logits[:, -1, :]  # Get logits for the last token\n",
    "\n",
    "# Calculate probabilities and log probabilities\n",
    "probabilities = torch.softmax(logits, dim=-1)\n",
    "log_probs = torch.log(probabilities)\n",
    "\n",
    "# Get top k candidates\n",
    "top_k = 500  # or 1000, as needed\n",
    "top_probabilities, top_indices = torch.topk(log_probs, top_k)\n",
    "\n",
    "# Decode the top tokens to words\n",
    "top_words = tokenizer.convert_ids_to_tokens(top_indices[0].tolist())\n",
    "\n",
    "# Display results\n",
    "probabilities = {}\n",
    "for word, prob in zip(top_words, top_probabilities[0].tolist()):\n",
    "    print(f\"Word: {word}, Log Probability: {prob:.4f}\")\n",
    "    probabilities[word] = prob\n",
    "    \n",
    "distribution = {k:probabilities[k] for k in 'ABCD'}\n",
    "\n",
    "print(distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T19:38:28.175817Z",
     "iopub.status.busy": "2024-08-11T19:38:28.175089Z",
     "iopub.status.idle": "2024-08-11T19:38:28.184167Z",
     "shell.execute_reply": "2024-08-11T19:38:28.183193Z",
     "shell.execute_reply.started": "2024-08-11T19:38:28.175785Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_distribution(prompt:str) -> dict:\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids)\n",
    "        logits = outputs.logits[:, -1, :]  # Get logits for the last token\n",
    "\n",
    "    # Calculate probabilities and log probabilities\n",
    "    probabilities = torch.softmax(logits, dim=-1)\n",
    "    log_probs = torch.log(probabilities)\n",
    "\n",
    "    # Get top k candidates\n",
    "    top_k = 50 \n",
    "    top_probabilities, top_indices = torch.topk(log_probs, top_k)\n",
    "\n",
    "    # Decode the top tokens to words\n",
    "    top_words = tokenizer.convert_ids_to_tokens(top_indices[0].tolist())\n",
    "\n",
    "    # Display results\n",
    "    probabilities = {}\n",
    "    for word, prob in zip(top_words, top_probabilities[0].tolist()):\n",
    "        # print(f\"Word: {word}, Log Probability: {prob:.4f}\")\n",
    "        probabilities[word] = prob\n",
    "\n",
    "    distribution = {k:probabilities[k] for k in 'ABCDE'}\n",
    "    \n",
    "    return distribution\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T20:23:02.798005Z",
     "iopub.status.busy": "2024-08-11T20:23:02.797289Z",
     "iopub.status.idle": "2024-08-11T20:23:02.805057Z",
     "shell.execute_reply": "2024-08-11T20:23:02.804091Z",
     "shell.execute_reply.started": "2024-08-11T20:23:02.797976Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_prompt(question, context=None, context_type=None):\n",
    "    context_str = ''\n",
    "    if context is not None:\n",
    "        # Context: \"Democrat\", \"Republican\", \"Independent\"\n",
    "        # Context Type: \"QA\", \"BIO\", \"PORTRAY\"\n",
    "        if context_type == 'QA':\n",
    "            context_options = {'republican': 'A', 'democrat': 'B', 'independent':'C'}\n",
    "            option = context_options.get(context.strip().lower(), 'D')\n",
    "            context_str = f\"\"\"\n",
    "Question: In politics today, do you consider yourself a\n",
    "A. Republican\n",
    "B. Democrat\n",
    "C. Independent\n",
    "D. Something else\n",
    "E. Refused\n",
    "Answer: {option}\n",
    "\"\"\"\n",
    "        elif context_type == 'BIO':\n",
    "            context_str = f\"\"\"\n",
    "Below you will be asked to provide a short description of your political affiliation and then answer some questions.\n",
    "Description: In politics today, I consider myself a {context.strip().title()}.\n",
    "\"\"\"\n",
    "        \n",
    "        elif context_type == 'PORTRAY':\n",
    "            context_str = f\"\"\"\n",
    "Answer the following question as if in politics today, you considered yourself a {context.strip().title()}.\n",
    "\"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "{context_str}\n",
    "    \n",
    "Question: {question}\n",
    "A. A great deal \n",
    "B. A fair amount\n",
    "C. Not too much\n",
    "D. Not at all\n",
    "E. Refused\n",
    "Answer:\n",
    "\"\"\"\n",
    "    \n",
    "    return prompt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T19:38:28.398544Z",
     "iopub.status.busy": "2024-08-11T19:38:28.398204Z",
     "iopub.status.idle": "2024-08-11T19:38:28.403969Z",
     "shell.execute_reply": "2024-08-11T19:38:28.403042Z",
     "shell.execute_reply.started": "2024-08-11T19:38:28.398516Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAnswer the following question as if in politics today, you considered yourself a Democrat.\\nQuestion: How much, if at all, do you think the ease with which people can legally obtain guns contributes to gun violence in the country today?\\nA. A great deal\\nB. A fair amount\\nC. Not too much\\nD. Not at all\\nE. Refused\\nAnswer:\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T19:38:28.653614Z",
     "iopub.status.busy": "2024-08-11T19:38:28.653264Z",
     "iopub.status.idle": "2024-08-11T19:38:31.522005Z",
     "shell.execute_reply": "2024-08-11T19:38:31.521040Z",
     "shell.execute_reply.started": "2024-08-11T19:38:28.653589Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': -2.000654935836792,\n",
       " 'B': -2.875412702560425,\n",
       " 'C': -3.5187442302703857,\n",
       " 'D': -3.3935420513153076,\n",
       " 'E': -3.0323398113250732}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_distribution(ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T19:46:56.056661Z",
     "iopub.status.busy": "2024-08-11T19:46:56.055988Z",
     "iopub.status.idle": "2024-08-11T19:46:56.060789Z",
     "shell.execute_reply": "2024-08-11T19:46:56.059895Z",
     "shell.execute_reply.started": "2024-08-11T19:46:56.056630Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt = generate_prompt(\"How much do you think video games contribute to violent behaviour?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T19:47:05.542395Z",
     "iopub.status.busy": "2024-08-11T19:47:05.542023Z",
     "iopub.status.idle": "2024-08-11T19:47:07.807765Z",
     "shell.execute_reply": "2024-08-11T19:47:07.806797Z",
     "shell.execute_reply.started": "2024-08-11T19:47:05.542366Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': -1.7732319831848145,\n",
       " 'B': -3.1909871101379395,\n",
       " 'C': -3.377291202545166,\n",
       " 'D': -3.7096409797668457,\n",
       " 'E': -3.5438637733459473}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_distribution(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T20:42:34.181715Z",
     "iopub.status.busy": "2024-08-11T20:42:34.181325Z",
     "iopub.status.idle": "2024-08-11T20:42:34.187496Z",
     "shell.execute_reply": "2024-08-11T20:42:34.186572Z",
     "shell.execute_reply.started": "2024-08-11T20:42:34.181683Z"
    }
   },
   "outputs": [],
   "source": [
    "def check_prompt(prompt_text):\n",
    "    contexts = ['Democrat', 'Republican', 'Independent']\n",
    "    context_types = ['QA', 'BIO', 'PORTRAY']\n",
    "\n",
    "    for c in contexts:\n",
    "        print(f'Context: {c}')\n",
    "        for ct in context_types:\n",
    "            prompt = generate_prompt(prompt_text, c, ct)\n",
    "            distribution = get_distribution(prompt)\n",
    "            print(f'\\t{ct}: {distribution}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T20:42:48.462954Z",
     "iopub.status.busy": "2024-08-11T20:42:48.462116Z",
     "iopub.status.idle": "2024-08-11T20:43:16.264139Z",
     "shell.execute_reply": "2024-08-11T20:43:16.263149Z",
     "shell.execute_reply.started": "2024-08-11T20:42:48.462919Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: Democrat\n",
      "\tQA: {'A': -2.1593713760375977, 'B': -3.45520281791687, 'C': -3.3548879623413086, 'D': -3.576727867126465, 'E': -4.272391319274902}\n",
      "\tBIO: {'A': -1.7771964073181152, 'B': -4.093850612640381, 'C': -4.028792858123779, 'D': -4.414580821990967, 'E': -3.8541295528411865}\n",
      "\tPORTRAY: {'A': -1.8704564571380615, 'B': -2.6371781826019287, 'C': -3.1757256984710693, 'D': -3.195455312728882, 'E': -3.276365041732788}\n",
      "Context: Republican\n",
      "\tQA: {'A': -1.946316123008728, 'B': -3.737745523452759, 'C': -3.5915892124176025, 'D': -3.673473596572876, 'E': -4.229767322540283}\n",
      "\tBIO: {'A': -1.746291160583496, 'B': -4.02139949798584, 'C': -4.000723838806152, 'D': -4.480439186096191, 'E': -3.8084592819213867}\n",
      "\tPORTRAY: {'A': -1.8931047916412354, 'B': -2.611757516860962, 'C': -3.1715452671051025, 'D': -3.3312361240386963, 'E': -3.200491189956665}\n",
      "Context: Independent\n",
      "\tQA: {'A': -2.1540613174438477, 'B': -3.9204225540161133, 'C': -2.971158027648926, 'D': -3.3068323135375977, 'E': -4.153826713562012}\n",
      "\tBIO: {'A': -1.762645959854126, 'B': -3.9537317752838135, 'C': -3.8385889530181885, 'D': -4.250183582305908, 'E': -3.8432886600494385}\n",
      "\tPORTRAY: {'A': -1.825565218925476, 'B': -2.719320058822632, 'C': -3.186532735824585, 'D': -3.3902111053466797, 'E': -3.376189947128296}\n"
     ]
    }
   ],
   "source": [
    "prompt_text = \"How much do you think video games contribute to violent behaviour?\"\n",
    "check_prompt(prompt_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T20:47:25.579697Z",
     "iopub.status.busy": "2024-08-11T20:47:25.579296Z",
     "iopub.status.idle": "2024-08-11T20:47:54.245192Z",
     "shell.execute_reply": "2024-08-11T20:47:54.244203Z",
     "shell.execute_reply.started": "2024-08-11T20:47:25.579665Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: Democrat\n",
      "\tQA: {'A': -2.0551371574401855, 'B': -3.158292293548584, 'C': -3.546720266342163, 'D': -3.681018352508545, 'E': -4.107490062713623}\n",
      "\tBIO: {'A': -1.7674928903579712, 'B': -4.125843524932861, 'C': -4.277702808380127, 'D': -4.331556797027588, 'E': -3.4211888313293457}\n",
      "\tPORTRAY: {'A': -1.999566912651062, 'B': -2.929170608520508, 'C': -3.4901695251464844, 'D': -3.074592351913452, 'E': -2.8992462158203125}\n",
      "Context: Republican\n",
      "\tQA: {'A': -1.8676550388336182, 'B': -3.7147390842437744, 'C': -3.8614256381988525, 'D': -3.8192923069000244, 'E': -4.027824878692627}\n",
      "\tBIO: {'A': -1.7549325227737427, 'B': -4.044834136962891, 'C': -4.205615997314453, 'D': -4.343362808227539, 'E': -3.3791427612304688}\n",
      "\tPORTRAY: {'A': -2.0296101570129395, 'B': -2.90671968460083, 'C': -3.4603562355041504, 'D': -3.1778531074523926, 'E': -2.858887195587158}\n",
      "Context: Independent\n",
      "\tQA: {'A': -2.1049602031707764, 'B': -3.5502307415008545, 'C': -2.991245985031128, 'D': -3.2880313396453857, 'E': -3.992804527282715}\n",
      "\tBIO: {'A': -1.7106765508651733, 'B': -3.984733819961548, 'C': -4.100462436676025, 'D': -4.178675174713135, 'E': -3.367536783218384}\n",
      "\tPORTRAY: {'A': -1.8572710752487183, 'B': -2.8727760314941406, 'C': -3.320657730102539, 'D': -3.133974075317383, 'E': -2.9037320613861084}\n"
     ]
    }
   ],
   "source": [
    "# Does context work on smaller parameter models like Gemma 2B?\n",
    "\n",
    "p2 = \"How much do you think same-sex couples should have the same legal rights as heterosexual couples?\"\n",
    "# Expected: Democrat - A or B \"great deal\"/\"fair deal\"\n",
    "# Republican - C or D \"not too much\"/\"not at all\"\n",
    "check_prompt(p2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T20:49:36.626677Z",
     "iopub.status.busy": "2024-08-11T20:49:36.626077Z",
     "iopub.status.idle": "2024-08-11T20:49:36.632377Z",
     "shell.execute_reply": "2024-08-11T20:49:36.631379Z",
     "shell.execute_reply.started": "2024-08-11T20:49:36.626643Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_prompts(prompt_text):\n",
    "    contexts = ['Democrat', 'Republican', 'Independent']\n",
    "    context_types = ['QA', 'BIO', 'PORTRAY']\n",
    "\n",
    "    for c in contexts:\n",
    "        print(f'Context: {c}')\n",
    "        for ct in context_types:\n",
    "            prompt = generate_prompt(prompt_text, c, ct)\n",
    "            print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T20:49:44.204118Z",
     "iopub.status.busy": "2024-08-11T20:49:44.203754Z",
     "iopub.status.idle": "2024-08-11T20:49:44.208918Z",
     "shell.execute_reply": "2024-08-11T20:49:44.207901Z",
     "shell.execute_reply.started": "2024-08-11T20:49:44.204087Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: Democrat\n",
      "\n",
      "\n",
      "Question: In politics today, do you consider yourself a\n",
      "A. Republican\n",
      "B. Democrat\n",
      "C. Independent\n",
      "D. Something else\n",
      "E. Refused\n",
      "Answer: B\n",
      "\n",
      "    \n",
      "Question: How much do you think same-sex couples should have the same legal rights as heterosexual couples?\n",
      "A. A great deal \n",
      "B. A fair amount\n",
      "C. Not too much\n",
      "D. Not at all\n",
      "E. Refused\n",
      "Answer:\n",
      "\n",
      "\n",
      "\n",
      "Below you will be asked to provide a short description of your political affiliation and then answer some questions.\n",
      "Description: In politics today, I consider myself a Democrat.\n",
      "\n",
      "    \n",
      "Question: How much do you think same-sex couples should have the same legal rights as heterosexual couples?\n",
      "A. A great deal \n",
      "B. A fair amount\n",
      "C. Not too much\n",
      "D. Not at all\n",
      "E. Refused\n",
      "Answer:\n",
      "\n",
      "\n",
      "\n",
      "Answer the following question as if in politics today, you considered yourself a Democrat.\n",
      "\n",
      "    \n",
      "Question: How much do you think same-sex couples should have the same legal rights as heterosexual couples?\n",
      "A. A great deal \n",
      "B. A fair amount\n",
      "C. Not too much\n",
      "D. Not at all\n",
      "E. Refused\n",
      "Answer:\n",
      "\n",
      "Context: Republican\n",
      "\n",
      "\n",
      "Question: In politics today, do you consider yourself a\n",
      "A. Republican\n",
      "B. Democrat\n",
      "C. Independent\n",
      "D. Something else\n",
      "E. Refused\n",
      "Answer: A\n",
      "\n",
      "    \n",
      "Question: How much do you think same-sex couples should have the same legal rights as heterosexual couples?\n",
      "A. A great deal \n",
      "B. A fair amount\n",
      "C. Not too much\n",
      "D. Not at all\n",
      "E. Refused\n",
      "Answer:\n",
      "\n",
      "\n",
      "\n",
      "Below you will be asked to provide a short description of your political affiliation and then answer some questions.\n",
      "Description: In politics today, I consider myself a Republican.\n",
      "\n",
      "    \n",
      "Question: How much do you think same-sex couples should have the same legal rights as heterosexual couples?\n",
      "A. A great deal \n",
      "B. A fair amount\n",
      "C. Not too much\n",
      "D. Not at all\n",
      "E. Refused\n",
      "Answer:\n",
      "\n",
      "\n",
      "\n",
      "Answer the following question as if in politics today, you considered yourself a Republican.\n",
      "\n",
      "    \n",
      "Question: How much do you think same-sex couples should have the same legal rights as heterosexual couples?\n",
      "A. A great deal \n",
      "B. A fair amount\n",
      "C. Not too much\n",
      "D. Not at all\n",
      "E. Refused\n",
      "Answer:\n",
      "\n",
      "Context: Independent\n",
      "\n",
      "\n",
      "Question: In politics today, do you consider yourself a\n",
      "A. Republican\n",
      "B. Democrat\n",
      "C. Independent\n",
      "D. Something else\n",
      "E. Refused\n",
      "Answer: C\n",
      "\n",
      "    \n",
      "Question: How much do you think same-sex couples should have the same legal rights as heterosexual couples?\n",
      "A. A great deal \n",
      "B. A fair amount\n",
      "C. Not too much\n",
      "D. Not at all\n",
      "E. Refused\n",
      "Answer:\n",
      "\n",
      "\n",
      "\n",
      "Below you will be asked to provide a short description of your political affiliation and then answer some questions.\n",
      "Description: In politics today, I consider myself a Independent.\n",
      "\n",
      "    \n",
      "Question: How much do you think same-sex couples should have the same legal rights as heterosexual couples?\n",
      "A. A great deal \n",
      "B. A fair amount\n",
      "C. Not too much\n",
      "D. Not at all\n",
      "E. Refused\n",
      "Answer:\n",
      "\n",
      "\n",
      "\n",
      "Answer the following question as if in politics today, you considered yourself a Independent.\n",
      "\n",
      "    \n",
      "Question: How much do you think same-sex couples should have the same legal rights as heterosexual couples?\n",
      "A. A great deal \n",
      "B. A fair amount\n",
      "C. Not too much\n",
      "D. Not at all\n",
      "E. Refused\n",
      "Answer:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_prompts(p2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does 2B struggle to emulate personalities/demographics?\n",
    "* (Should confirm with more prompts, however;) this should be expected - given the low number of parameters \n",
    "    * Do bigger Gemma2 models understand the context we provide?\n",
    "\n",
    "In comparison, GPT-4o;\n",
    "[ChatGPT](https://chatgpt.com/share/b7e4e5d8-f7d8-4d52-a69b-37dc261bffd0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "isSourceIdPinned": true,
     "modelId": 76277,
     "modelInstanceId": 72253,
     "sourceId": 85994,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30747,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
