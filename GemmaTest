{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":85994,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":72253,"modelId":76277}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-11T19:32:14.093778Z","iopub.execute_input":"2024-08-11T19:32:14.094516Z","iopub.status.idle":"2024-08-11T19:32:15.056947Z","shell.execute_reply.started":"2024-08-11T19:32:14.094479Z","shell.execute_reply":"2024-08-11T19:32:15.055991Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/gemma-2/transformers/gemma-2-2b/1/model.safetensors.index.json\n/kaggle/input/gemma-2/transformers/gemma-2-2b/1/model-00003-of-00003.safetensors\n/kaggle/input/gemma-2/transformers/gemma-2-2b/1/config.json\n/kaggle/input/gemma-2/transformers/gemma-2-2b/1/README.md\n/kaggle/input/gemma-2/transformers/gemma-2-2b/1/tokenizer.json\n/kaggle/input/gemma-2/transformers/gemma-2-2b/1/model-00001-of-00003.safetensors\n/kaggle/input/gemma-2/transformers/gemma-2-2b/1/tokenizer_config.json\n/kaggle/input/gemma-2/transformers/gemma-2-2b/1/gitattributes\n/kaggle/input/gemma-2/transformers/gemma-2-2b/1/model-00002-of-00003.safetensors\n/kaggle/input/gemma-2/transformers/gemma-2-2b/1/special_tokens_map.json\n/kaggle/input/gemma-2/transformers/gemma-2-2b/1/tokenizer.model\n/kaggle/input/gemma-2/transformers/gemma-2-2b/1/generation_config.json\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer\n\nmodel = AutoModelForCausalLM.from_pretrained('/kaggle/input/gemma-2/transformers/gemma-2-2b/1/')\ntokenizer = AutoTokenizer.from_pretrained('/kaggle/input/gemma-2/transformers/gemma-2-2b/1/')","metadata":{"execution":{"iopub.status.busy":"2024-08-11T19:37:12.401361Z","iopub.execute_input":"2024-08-11T19:37:12.401729Z","iopub.status.idle":"2024-08-11T19:37:18.330438Z","shell.execute_reply.started":"2024-08-11T19:37:12.401698Z","shell.execute_reply":"2024-08-11T19:37:18.329638Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8f1e346526d4f028c23b9dda50b754d"}},"metadata":{}}]},{"cell_type":"code","source":"ip = \"\"\"\nAnswer the following question as if in politics today, you considered yourself a Democrat.\nQuestion: How much, if at all, do you think the ease with which people can legally obtain guns contributes to gun violence in the country today?\nA. A great deal\nB. A fair amount\nC. Not too much\nD. Not at all\nE. Refused\nAnswer:\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-08-11T19:37:39.697876Z","iopub.execute_input":"2024-08-11T19:37:39.698720Z","iopub.status.idle":"2024-08-11T19:37:39.703223Z","shell.execute_reply.started":"2024-08-11T19:37:39.698688Z","shell.execute_reply":"2024-08-11T19:37:39.702178Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"input_ids = tokenizer.encode(ip, return_tensors='pt')","metadata":{"execution":{"iopub.status.busy":"2024-08-11T19:33:41.116283Z","iopub.execute_input":"2024-08-11T19:33:41.116548Z","iopub.status.idle":"2024-08-11T19:33:41.129204Z","shell.execute_reply.started":"2024-08-11T19:33:41.116526Z","shell.execute_reply":"2024-08-11T19:33:41.128501Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import torch\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\n\nmodel = model.to(device)\ninput_ids = input_ids.to(device)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-11T19:33:41.130405Z","iopub.execute_input":"2024-08-11T19:33:41.130705Z","iopub.status.idle":"2024-08-11T19:33:44.166480Z","shell.execute_reply.started":"2024-08-11T19:33:41.130677Z","shell.execute_reply":"2024-08-11T19:33:44.165682Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"with torch.no_grad():\n    outputs = model(input_ids)\n    logits = outputs.logits[:, -1, :]  # Get logits for the last token\n\n# Calculate probabilities and log probabilities\nprobabilities = torch.softmax(logits, dim=-1)\nlog_probs = torch.log(probabilities)\n\n# Get top k candidates\ntop_k = 500  # or 1000, as needed\ntop_probabilities, top_indices = torch.topk(log_probs, top_k)\n\n# Decode the top tokens to words\ntop_words = tokenizer.convert_ids_to_tokens(top_indices[0].tolist())\n\n# Display results\nprobabilities = {}\nfor word, prob in zip(top_words, top_probabilities[0].tolist()):\n    print(f\"Word: {word}, Log Probability: {prob:.4f}\")\n    probabilities[word] = prob\n    \ndistribution = {k:probabilities[k] for k in 'ABCD'}\n\nprint(distribution)","metadata":{"execution":{"iopub.status.busy":"2024-08-11T19:33:44.167620Z","iopub.execute_input":"2024-08-11T19:33:44.167918Z","iopub.status.idle":"2024-08-11T19:33:44.798735Z","shell.execute_reply.started":"2024-08-11T19:33:44.167893Z","shell.execute_reply":"2024-08-11T19:33:44.797823Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Word: A, Log Probability: -2.0007\nWord: Question, Log Probability: -2.1934\nWord: B, Log Probability: -2.8754\nWord: E, Log Probability: -3.0324\nWord: Answer, Log Probability: -3.2791\nWord: The, Log Probability: -3.3108\nWord: D, Log Probability: -3.3936\nWord: C, Log Probability: -3.5188\nWord: If, Log Probability: -3.7469\nWord: 1, Log Probability: -3.7900\nWord: How, Log Probability: -3.9272\nWord: ▁, Log Probability: -3.9367\nWord: F, Log Probability: -3.9881\nWord: What, Log Probability: -4.3471\nWord: (, Log Probability: -4.3614\nWord: I, Log Probability: -4.4500\nWord: 2, Log Probability: -4.5167\nWord: In, Log Probability: -4.5579\nWord: Which, Log Probability: -4.5938\nWord: You, Log Probability: -4.6907\nWord: This, Log Probability: -4.7020\nWord: Your, Log Probability: -4.7382\nWord: Q, Log Probability: -4.8104\nWord: Explanation, Log Probability: -4.8984\nWord: <strong>, Log Probability: -4.9561\nWord: Source, Log Probability: -5.0454\nWord: Correct, Log Probability: -5.0765\nWord: According, Log Probability: -5.1325\nWord: 3, Log Probability: -5.1326\nWord: 6, Log Probability: -5.2613\nWord: 4, Log Probability: -5.2957\nWord: Please, Log Probability: -5.3424\nWord: 5, Log Probability: -5.3916\nWord: Click, Log Probability: -5.3959\nWord: To, Log Probability: -5.4493\nWord: As, Log Probability: -5.4733\nWord: [, Log Probability: -5.4845\nWord: *, Log Probability: -5.5123\nWord: When, Log Probability: -5.6369\nWord: Note, Log Probability: -5.6430\nWord: https, Log Probability: -5.6494\nWord: a, Log Probability: -5.6744\nWord: For, Log Probability: -5.7006\nWord: 0, Log Probability: -5.7079\nWord: Percent, Log Probability: -5.7134\nWord: Now, Log Probability: -5.7441\nWord: View, Log Probability: -5.7445\nWord: 7, Log Probability: -5.8006\nWord: We, Log Probability: -5.8213\nWord: It, Log Probability: -5.8583\nWord: <b>, Log Probability: -5.8660\nWord: %, Log Probability: -5.8830\nWord: Thank, Log Probability: -5.8965\nWord: \", Log Probability: -5.9142\nWord: Option, Log Probability: -5.9470\nWord: -, Log Probability: -5.9479\nWord: <, Log Probability: -5.9488\nWord: Next, Log Probability: -5.9699\nWord: There, Log Probability: -5.9788\nWord: Ref, Log Probability: -6.0309\nWord: Based, Log Probability: -6.0329\nWord: 8, Log Probability: -6.0455\nWord: Percentage, Log Probability: -6.0535\nWord: Select, Log Probability: -6.1322\nWord: •, Log Probability: -6.2515\nWord: Let, Log Probability: -6.2837\nWord: Show, Log Probability: -6.3395\nWord: Not, Log Probability: -6.3445\nWord: Do, Log Probability: -6.4153\nWord: Here, Log Probability: -6.4271\nWord: <em>, Log Probability: -6.4507\nWord: ________________, Log Probability: -6.4702\nWord: 9, Log Probability: -6.4761\nWord: Why, Log Probability: -6.5067\nWord: None, Log Probability: -6.5096\nWord: Total, Log Probability: -6.5452\nWord: ▁▁, Log Probability: -6.5622\nWord: http, Log Probability: -6.5784\nWord: “, Log Probability: -6.6204\nWord: An, Log Probability: -6.6226\nWord: No, Log Probability: -6.6855\nWord: Most, Log Probability: -6.6878\nWord: More, Log Probability: -6.7036\nWord: QUESTION, Log Probability: -6.7394\nWord: ----------------, Log Probability: -6.7774\nWord: Thanks, Log Probability: -6.7836\nWord: ​, Log Probability: -6.7850\nWord: Given, Log Probability: -6.7862\nWord: ▁▁▁▁, Log Probability: -6.8279\nWord: Data, Log Probability: -6.8521\nWord: Suppose, Log Probability: -6.8561\nWord: ., Log Probability: -6.8641\nWord: G, Log Probability: -6.8868\nWord: Score, Log Probability: -6.9251\nWord: Instructions, Log Probability: -6.9410\nWord: Key, Log Probability: -6.9856\nWord: <eos>, Log Probability: -6.9909\nWord: Choose, Log Probability: -7.0081\nWord: Number, Log Probability: -7.0434\nWord: Survey, Log Probability: -7.0656\nWord: \\, Log Probability: -7.0940\nWord: At, Log Probability: -7.1167\nWord: So, Log Probability: -7.1278\nWord: Write, Log Probability: -7.1592\nWord: Type, Log Probability: -7.1593\nWord: See, Log Probability: -7.1770\nWord: People, Log Probability: -7.1794\nWord: On, Log Probability: -7.1809\nWord: Step, Log Probability: -7.1969\nWord: Yes, Log Probability: -7.1984\nWord: One, Log Probability: -7.2398\nWord: e, Log Probability: -7.2446\nWord: Share, Log Probability: -7.2541\nWord: Analysis, Log Probability: -7.2755\nWord: Well, Log Probability: -7.2798\nWord: Page, Log Probability: -7.2805\nWord: First, Log Probability: -7.3134\nWord: And, Log Probability: -7.3300\nWord: With, Log Probability: -7.3440\nWord: Did, Log Probability: -7.3660\nWord: Questions, Log Probability: -7.3675\nWord: Check, Log Probability: -7.3687\nWord: All, Log Probability: -7.3728\nWord: After, Log Probability: -7.3745\nWord: Okay, Log Probability: -7.3857\nWord: Explain, Log Probability: -7.3965\nWord: From, Log Probability: -7.4243\nWord: $, Log Probability: -7.4262\nWord: Code, Log Probability: -7.4375\nWord: #, Log Probability: -7.4385\nWord: Part, Log Probability: -7.4432\nWord: Directions, Log Probability: -7.4534\nWord: Use, Log Probability: -7.4809\nWord: Mean, Log Probability: -7.4933\nWord: Response, Log Probability: -7.5028\nWord: Is, Log Probability: -7.5179\nWord: Reference, Log Probability: -7.5232\nWord: <h2>, Log Probability: -7.5802\nWord: Among, Log Probability: -7.5974\nWord: Comment, Log Probability: -7.5983\nWord: Take, Log Probability: -7.6043\nWord: Since, Log Probability: -7.6107\nWord: Incorrect, Log Probability: -7.6253\nWord: Refer, Log Probability: -7.6438\nWord: About, Log Probability: -7.6501\nWord: My, Log Probability: -7.6531\nWord: question, Log Probability: -7.6685\nWord: Read, Log Probability: -7.6760\nWord: Political, Log Probability: -7.6865\nWord: Research, Log Probability: -7.6930\nWord: Go, Log Probability: -7.6990\nWord: Democrats, Log Probability: -7.7054\nWord: Using, Log Probability: -7.7192\nWord: By, Log Probability: -7.7213\nWord: <code>, Log Probability: -7.7404\nWord: Graph, Log Probability: -7.7541\nWord: +, Log Probability: -7.7825\nWord: Figure, Log Probability: -7.7949\nWord: Are, Log Probability: -7.8050\nWord: --, Log Probability: -7.8078\nWord: Of, Log Probability: -7.8344\nWord: b, Log Probability: -7.8517\nWord: References, Log Probability: -7.8939\nWord: Loading, Log Probability: -7.9091\nWord: >, Log Probability: -7.9331\nWord: Hint, Log Probability: -7.9348\nWord: Although, Log Probability: -7.9369\nWord: Consider, Log Probability: -7.9462\nWord: ================, Log Probability: -7.9498\nWord: Per, Log Probability: -7.9544\nWord: Results, Log Probability: -7.9623\nWord: Because, Log Probability: -7.9677\nWord: Enter, Log Probability: -7.9866\nWord: Category, Log Probability: -7.9920\nWord: Add, Log Probability: -7.9981\nWord: Choice, Log Probability: -8.0055\nWord: Just, Log Probability: -8.0152\nWord: Then, Log Probability: -8.0272\nWord: Answers, Log Probability: -8.0281\nWord: Rate, Log Probability: -8.0361\nWord: That, Log Probability: -8.0363\nWord: Poll, Log Probability: -8.0380\nWord: the, Log Probability: -8.0573\nWord: <h3>, Log Probability: -8.0681\nWord: Reason, Log Probability: -8.0894\nWord: Some, Log Probability: -8.1183\nWord: Average, Log Probability: -8.1330\nWord: Result, Log Probability: -8.1552\nWord: ©, Log Probability: -8.1656\nWord: Download, Log Probability: -8.1725\nWord: <i>, Log Probability: -8.1946\nWord: Back, Log Probability: -8.1957\nWord: Very, Log Probability: -8.2007\nWord: Vote, Log Probability: -8.2110\nWord: ```, Log Probability: -8.2264\nWord: Open, Log Probability: -8.2496\nWord: Who, Log Probability: -8.2571\nWord: {, Log Probability: -8.2699\nWord: ..., Log Probability: -8.2779\nWord: Un, Log Probability: -8.2837\nWord: Topic, Log Probability: -8.2866\nWord: Selected, Log Probability: -8.2979\nWord: Related, Log Probability: -8.3085\nWord: REF, Log Probability: -8.3124\nWord: Report, Log Probability: -8.3157\nWord: Americans, Log Probability: -8.3200\nWord: Gun, Log Probability: -8.3290\nWord: Find, Log Probability: -8.3299\nWord: Table, Log Probability: -8.3355\nWord: Notes, Log Probability: -8.3567\nWord: Instruction, Log Probability: -8.3591\nWord: Link, Log Probability: -8.3666\nWord: Close, Log Probability: -8.3707\nWord: Look, Log Probability: -8.3768\nWord: Copyright, Log Probability: -8.3857\nWord: Identify, Log Probability: -8.3935\nWord: These, Log Probability: -8.3989\nWord: Once, Log Probability: -8.4006\nWord: Comments, Log Probability: -8.4014\nWord: ▁▁▁, Log Probability: -8.4063\nWord: $\\, Log Probability: -8.4118\nWord: Image, Log Probability: -8.4262\nWord: Tell, Log Probability: -8.4448\nWord: Description, Log Probability: -8.4478\nWord: Dear, Log Probability: -8.4489\nWord: O, Log Probability: -8.4722\nWord: Turn, Log Probability: -8.4818\nWord: ANSWER, Log Probability: -8.4827\nWord: Think, Log Probability: -8.5097\nWord: =, Log Probability: -8.5155\nWord: Would, Log Probability: -8.5162\nWord: Options, Log Probability: -8.5182\nWord: Previous, Log Probability: -8.5399\nWord: Many, Log Probability: -8.5413\nWord: Today, Log Probability: -8.5631\nWord: Good, Log Probability: -8.5663\nWord: While, Log Probability: -8.5665\nWord: Exhibit, Log Probability: -8.5689\nWord: Last, Log Probability: -8.5721\nWord: N, Log Probability: -8.5777\nWord: Should, Log Probability: -8.5780\nWord: ---, Log Probability: -8.5787\nWord: Can, Log Probability: -8.5882\nWord: CNN, Log Probability: -8.5961\nWord: Calculate, Log Probability: -8.6024\nWord: Group, Log Probability: -8.6056\nWord: f, Log Probability: -8.6068\nWord: Text, Log Probability: -8.6075\nWord: Only, Log Probability: -8.6114\nWord: Transcript, Log Probability: -8.6120\nWord: Before, Log Probability: -8.6141\nWord: , Log Probability: -8.6239\nWord: –, Log Probability: -8.6328\nWord: Overall, Log Probability: -8.6331\nWord: Have, Log Probability: -8.6364\nWord: <u>, Log Probability: -8.6388\nWord: Background, Log Probability: -8.6521\nWord: —, Log Probability: -8.6541\nWord: Complete, Log Probability: -8.6546\nWord: Republicans, Log Probability: -8.6551\nWord: if, Log Probability: -8.6565\nWord: Gender, Log Probability: -8.6566\nWord: Statement, Log Probability: -8.6652\nWord: \t, Log Probability: -8.6766\nWord: Name, Log Probability: -8.6767\nWord: Great, Log Probability: -8.6965\nWord: Give, Log Probability: -8.7027\nWord: c, Log Probability: -8.7148\nWord: Guns, Log Probability: -8.7158\nWord: ref, Log Probability: -8.7281\nWord: Summary, Log Probability: -8.7283\nWord: ▁Question, Log Probability: -8.7296\nWord: Democratic, Log Probability: -8.7317\nWord: Continue, Log Probability: -8.7386\nWord: Chart, Log Probability: -8.7517\nWord: Feedback, Log Probability: -8.7559\nWord: President, Log Probability: -8.7571\nWord: Frequency, Log Probability: -8.7574\nWord: ?, Log Probability: -8.7603\nWord: <h4>, Log Probability: -8.7613\nWord: Conclusion, Log Probability: -8.7632\nWord: Submitted, Log Probability: -8.7741\nWord: Make, Log Probability: -8.7779\nWord: Don, Log Probability: -8.7819\nWord: Choices, Log Probability: -8.7869\nWord: Reflect, Log Probability: -8.7910\nWord: Right, Log Probability: -8.7953\nWord: Credit, Log Probability: -8.7954\nWord: Slide, Log Probability: -8.7971\nWord: Analyze, Log Probability: -8.8176\nWord: Get, Log Probability: -8.8211\nWord: Insert, Log Probability: -8.8298\nWord: Place, Log Probability: -8.8353\nWord: Trans, Log Probability: -8.8367\nWord: Asked, Log Probability: -8.8381\nWord: Below, Log Probability: -8.8420\nWord: Does, Log Probability: -8.8514\nWord: Again, Log Probability: -8.8595\nWord: Exp, Log Probability: -8.8642\nWord: &, Log Probability: -8.8825\nWord: Expected, Log Probability: -8.8869\nWord: Final, Log Probability: -8.8953\nWord: percent, Log Probability: -8.9021\nWord: Discussion, Log Probability: -8.9118\nWord: NOTE, Log Probability: -8.9138\nWord: Example, Log Probability: -8.9244\nWord: Our, Log Probability: -8.9274\nWord: J, Log Probability: -8.9290\nWord: |, Log Probability: -8.9381\nWord: how, Log Probability: -8.9467\nWord: Fill, Log Probability: -8.9562\nWord: Age, Log Probability: -8.9660\nWord: Politics, Log Probability: -8.9696\nWord: ▁▁▁▁▁, Log Probability: -8.9706\nWord: Bull, Log Probability: -8.9713\nWord: Out, Log Probability: -8.9718\nWord: Where, Log Probability: -8.9760\nWord: Ex, Log Probability: -8.9761\nWord: Assuming, Log Probability: -8.9871\nWord: Sample, Log Probability: -8.9927\nWord: Drag, Log Probability: -8.9949\nWord: Factor, Log Probability: -9.0017\nWord: </blockquote>, Log Probability: -9.0058\nWord: Other, Log Probability: -9.0078\nWord: Another, Log Probability: -9.0167\nWord: Strongly, Log Probability: -9.0479\nWord: Method, Log Probability: -9.0481\nWord: ***, Log Probability: -9.0514\nWord: Multiple, Log Probability: -9.0555\nWord: <h1>, Log Probability: -9.0562\nWord: Over, Log Probability: -9.0624\nWord: </, Log Probability: -9.0671\nWord: **, Log Probability: -9.0995\nWord: Re, Log Probability: -9.1002\nWord: _, Log Probability: -9.1053\nWord: Opinion, Log Probability: -9.1057\nWord: Determine, Log Probability: -9.1101\nWord: Save, Log Probability: -9.1277\nWord: Assume, Log Probability: -9.1285\nWord: Looking, Log Probability: -9.1321\nWord: Submit, Log Probability: -9.1323\nWord: Got, Log Probability: -9.1601\nWord: Even, Log Probability: -9.1678\nWord: Box, Log Probability: -9.1744\nWord: Ind, Log Probability: -9.1761\nWord: Median, Log Probability: -9.1771\nWord: ___, Log Probability: -9.1786\nWord: H, Log Probability: -9.1854\nWord: Trump, Log Probability: -9.1872\nWord: Exit, Log Probability: -9.1958\nWord: ', Log Probability: -9.2313\nWord: Direction, Log Probability: -9.2424\nWord: Try, Log Probability: -9.2441\nWord: V, Log Probability: -9.2525\nWord: Sorry, Log Probability: -9.2535\nWord: ﻿, Log Probability: -9.2572\nWord: Less, Log Probability: -9.2696\nWord: Study, Log Probability: -9.2719\nWord: They, Log Probability: -9.2745\nWord: Problem, Log Probability: -9.2952\nWord: Record, Log Probability: -9.3065\nWord: Appendix, Log Probability: -9.3074\nWord: Was, Log Probability: -9.3133\nWord: ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁, Log Probability: -9.3134\nWord: Activity, Log Probability: -9.3218\nWord: Statistics, Log Probability: -9.3259\nWord: Level, Log Probability: -9.3350\nWord: Student, Log Probability: -9.3427\nWord: Views, Log Probability: -9.3432\nWord: Joe, Log Probability: -9.3489\nWord: Section, Log Probability: -9.3595\nWord: __, Log Probability: -9.3606\nWord: Sources, Log Probability: -9.3617\nWord: Introduction, Log Probability: -9.3626\nWord: /, Log Probability: -9.3653\nWord: your, Log Probability: -9.3682\nWord: Base, Log Probability: -9.3707\nWord: ****************, Log Probability: -9.3745\nWord: Public, Log Probability: -9.3763\nWord: Proportion, Log Probability: -9.3811\nWord: Responses, Log Probability: -9.3854\nWord: American, Log Probability: -9.3857\nWord: Accept, Log Probability: -9.3899\nWord: Display, Log Probability: -9.3917\nWord: Excellent, Log Probability: -9.4019\nWord: Be, Log Probability: -9.4057\nWord: ____, Log Probability: -9.4124\nWord: True, Log Probability: -9.4196\nWord: Help, Log Probability: -9.4382\nWord: NONE, Log Probability: -9.4400\nWord: Blank, Log Probability: -9.4511\nWord: Confidence, Log Probability: -9.4557\nWord: Keep, Log Probability: -9.4579\nWord: ▁▁▁▁▁▁▁▁, Log Probability: -9.4634\nWord: :, Log Probability: -9.4636\nWord: Hello, Log Probability: -9.4683\nWord: @, Log Probability: -9.4809\nWord: Biden, Log Probability: -9.4905\nWord: Ans, Log Probability: -9.5098\nWord: Time, Log Probability: -9.5120\nWord: Voting, Log Probability: -9.5197\nWord: show, Log Probability: -9.5226\nWord: Want, Log Probability: -9.5428\nWord: U, Log Probability: -9.5458\nWord: Researchers, Log Probability: -9.5513\nWord: Item, Log Probability: -9.5581\nWord: Approximately, Log Probability: -9.5693\nWord: which, Log Probability: -9.5739\nWord: Preview, Log Probability: -9.5761\nWord: Grade, Log Probability: -9.5806\nWord: Rationale, Log Probability: -9.5808\nWord: Hi, Log Probability: -9.5853\nWord: Compare, Log Probability: -9.5859\nWord: to, Log Probability: -9.5872\nWord: Solution, Log Probability: -9.5873\nWord: Getty, Log Probability: -9.5887\nWord: Screen, Log Probability: -9.5927\nWord: Like, Log Probability: -9.5971\nWord: Full, Log Probability: -9.6035\nWord: Democracy, Log Probability: -9.6198\nWord: Interpret, Log Probability: -9.6302\nWord: Agree, Log Probability: -9.6339\nWord: www, Log Probability: -9.6444\nWord: </code>, Log Probability: -9.6467\nWord: Additional, Log Probability: -9.6516\nWord: $$, Log Probability: -9.6713\nWord: Graphic, Log Probability: -9.6727\nWord: Remember, Log Probability: -9.6731\nWord: Follow, Log Probability: -9.6767\nWord: Two, Log Probability: -9.6777\nWord: New, Log Probability: -9.6793\nWord: Scenario, Log Probability: -9.6854\nWord: Candidate, Log Probability: -9.6874\nWord: S, Log Probability: -9.6887\nWord: Unfortunately, Log Probability: -9.6929\nWord: Moderate, Log Probability: -9.6948\nWord: Majority, Log Probability: -9.6993\nWord: Demographic, Log Probability: -9.7011\nWord: Official, Log Probability: -9.7099\nWord: M, Log Probability: -9.7243\nWord: Con, Log Probability: -9.7245\nWord: Fact, Log Probability: -9.7254\nWord: Test, Log Probability: -9.7267\nWord: End, Log Probability: -9.7279\nWord: Create, Log Probability: -9.7295\nWord: Content, Log Probability: -9.7327\nWord: Exercise, Log Probability: -9.7350\nWord: Media, Log Probability: -9.7497\nWord: _____, Log Probability: -9.7516\nWord: Difficulty, Log Probability: -9.7526\nWord: Pick, Log Probability: -9.7552\nWord: Notice, Log Probability: -9.7580\nWord: i, Log Probability: -9.7770\nWord: Margin, Log Probability: -9.7790\nWord: Dist, Log Probability: -9.7824\nWord: Top, Log Probability: -9.7859\nWord: ▁▁▁▁▁▁, Log Probability: -9.7883\nWord: Population, Log Probability: -9.7914\nWord: Send, Log Probability: -9.8037\nWord: Could, Log Probability: -9.8081\nWord: ~, Log Probability: -9.8082\nWord: AP, Log Probability: -9.8100\nWord: Under, Log Probability: -9.8142\nWord: %%, Log Probability: -9.8345\nWord: R, Log Probability: -9.8386\nWord: Republican, Log Probability: -9.8445\nWord: answer, Log Probability: -9.8456\nWord: Put, Log Probability: -9.8545\nWord: ▁A, Log Probability: -9.8581\nWord: Purchase, Log Probability: -9.8599\nWord: Those, Log Probability: -9.8629\nWord: Recall, Log Probability: -9.8655\nWord: Students, Log Probability: -9.8659\nWord: Rating, Log Probability: -9.8679\nWord: Non, Log Probability: -9.8680\nWord: and, Log Probability: -9.8687\nWord: Polling, Log Probability: -9.8715\nWord: Press, Log Probability: -9.8828\nWord: Me, Log Probability: -9.8842\nWord: [toxicity=0], Log Probability: -9.8898\nWord: d, Log Probability: -9.8904\nWord: Posted, Log Probability: -9.8988\nWord: Current, Log Probability: -9.9031\nWord: Scoring, Log Probability: -9.9184\nWord: -----, Log Probability: -9.9209\nWord: Ok, Log Probability: -9.9254\nWord: But, Log Probability: -9.9344\nWord: Least, Log Probability: -9.9344\nWord: ————————————————, Log Probability: -9.9353\nWord: Ask, Log Probability: -9.9353\nWord: THE, Log Probability: -9.9490\nWord: Message, Log Probability: -9.9615\nWord: OK, Log Probability: -9.9622\nWord: Evaluate, Log Probability: -9.9637\nWord: Questionnaire, Log Probability: -9.9672\nWord: Jus, Log Probability: -9.9711\nWord: Finally, Log Probability: -9.9713\nWord: Whether, Log Probability: -9.9723\nWord: >>, Log Probability: -9.9750\nWord: Examine, Log Probability: -9.9799\n{'A': -2.000676155090332, 'B': -2.875433921813965, 'C': -3.5187597274780273, 'D': -3.3935651779174805}\n","output_type":"stream"}]},{"cell_type":"code","source":"def get_distribution(prompt:str) -> dict:\n    input_ids = tokenizer.encode(prompt, return_tensors='pt')\n\n    with torch.no_grad():\n        outputs = model(input_ids)\n        logits = outputs.logits[:, -1, :]  # Get logits for the last token\n\n    # Calculate probabilities and log probabilities\n    probabilities = torch.softmax(logits, dim=-1)\n    log_probs = torch.log(probabilities)\n\n    # Get top k candidates\n    top_k = 50 \n    top_probabilities, top_indices = torch.topk(log_probs, top_k)\n\n    # Decode the top tokens to words\n    top_words = tokenizer.convert_ids_to_tokens(top_indices[0].tolist())\n\n    # Display results\n    probabilities = {}\n    for word, prob in zip(top_words, top_probabilities[0].tolist()):\n        # print(f\"Word: {word}, Log Probability: {prob:.4f}\")\n        probabilities[word] = prob\n\n    distribution = {k:probabilities[k] for k in 'ABCDE'}\n    \n    return distribution\n    ","metadata":{"execution":{"iopub.status.busy":"2024-08-11T19:38:28.175089Z","iopub.execute_input":"2024-08-11T19:38:28.175817Z","iopub.status.idle":"2024-08-11T19:38:28.184167Z","shell.execute_reply.started":"2024-08-11T19:38:28.175785Z","shell.execute_reply":"2024-08-11T19:38:28.183193Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def generate_prompt(question, context=None, context_type=None):\n    context_str = ''\n    if context is not None:\n        pass\n    \n    prompt = f\"\"\"\n{context_str}\n    \nQuestion: {question}\nA. A great deal \nB. A fair amount\nC. Not too much\nD. Not at all\nE. Refused\nAnswer:\n\"\"\"\n    return prompt","metadata":{"execution":{"iopub.status.busy":"2024-08-11T19:44:33.458547Z","iopub.execute_input":"2024-08-11T19:44:33.459236Z","iopub.status.idle":"2024-08-11T19:44:33.464155Z","shell.execute_reply.started":"2024-08-11T19:44:33.459203Z","shell.execute_reply":"2024-08-11T19:44:33.463241Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"ip","metadata":{"execution":{"iopub.status.busy":"2024-08-11T19:38:28.398204Z","iopub.execute_input":"2024-08-11T19:38:28.398544Z","iopub.status.idle":"2024-08-11T19:38:28.403969Z","shell.execute_reply.started":"2024-08-11T19:38:28.398516Z","shell.execute_reply":"2024-08-11T19:38:28.403042Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"'\\nAnswer the following question as if in politics today, you considered yourself a Democrat.\\nQuestion: How much, if at all, do you think the ease with which people can legally obtain guns contributes to gun violence in the country today?\\nA. A great deal\\nB. A fair amount\\nC. Not too much\\nD. Not at all\\nE. Refused\\nAnswer:\\n'"},"metadata":{}}]},{"cell_type":"code","source":"get_distribution(ip)","metadata":{"execution":{"iopub.status.busy":"2024-08-11T19:38:28.653264Z","iopub.execute_input":"2024-08-11T19:38:28.653614Z","iopub.status.idle":"2024-08-11T19:38:31.522005Z","shell.execute_reply.started":"2024-08-11T19:38:28.653589Z","shell.execute_reply":"2024-08-11T19:38:31.521040Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"{'A': -2.000654935836792,\n 'B': -2.875412702560425,\n 'C': -3.5187442302703857,\n 'D': -3.3935420513153076,\n 'E': -3.0323398113250732}"},"metadata":{}}]},{"cell_type":"code","source":"prompt = generate_prompt(\"How much do you think video games contribute to violent behaviour?\")","metadata":{"execution":{"iopub.status.busy":"2024-08-11T19:46:56.055988Z","iopub.execute_input":"2024-08-11T19:46:56.056661Z","iopub.status.idle":"2024-08-11T19:46:56.060789Z","shell.execute_reply.started":"2024-08-11T19:46:56.056630Z","shell.execute_reply":"2024-08-11T19:46:56.059895Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"get_distribution(prompt)","metadata":{"execution":{"iopub.status.busy":"2024-08-11T19:47:05.542023Z","iopub.execute_input":"2024-08-11T19:47:05.542395Z","iopub.status.idle":"2024-08-11T19:47:07.807765Z","shell.execute_reply.started":"2024-08-11T19:47:05.542366Z","shell.execute_reply":"2024-08-11T19:47:07.806797Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"{'A': -1.7732319831848145,\n 'B': -3.1909871101379395,\n 'C': -3.377291202545166,\n 'D': -3.7096409797668457,\n 'E': -3.5438637733459473}"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}